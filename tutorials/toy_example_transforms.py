"""
This tutorial showcases on a toy model how we use sequences of transforms to
prepare data as neural network input. The toy model is designed to have
similar properties as the GW parameter estimation problem. As forward model
we use a harmonic oscillator that is initially at rest, and then excited with
an infinitesimally short pulse. After excitation, it exhibits a damped
oscillation.

The forward model has 2 intrinsic parameters:
    omega0 :    resonance frequency of undamped oscillator
    beta :      damping factor

Based on these parameters a dataset with raw data is generated. This
corresponds to generating a GW dataset of raw waveforms with intrinsic
parameters sampled from a prior, but extrinsic ones set to fiducial values.

We implement transformations for 3 cases:

Training Transformations:       Raw Data       --->  Network input
Generation of Observations:     Network input  --->  Observation
Inference Transformations:      Observation    --->  Network input

The training transformations transform a dataset of raw data to fully
processed data suitable as input for the neural network. This will be used in
training to prepare the training data. The inference transformations
transform observed data to the network input format in an analogous way to
the training transformation. This will be used at inference time to prepare
the observed data accordingly. The generation of observations is a helper
transform, that generates simulated observations based on data in the network
input format.

Training Transformations
------------------------
Raw Data ---> Network input

The network input is generated by projecting the raw signal onto Nd
different detectors, whitening the signals and adding noise. This is realized
by the following sequence of transforms.

* Sample extrinsic parameters (the Nd arrival times {t0, t1, ...} in the Nd
  dectectors) from the extrinsic prior. Project them onto the detectors by
  shifting the raw signal in each detector by the corresponding time.
  In total, the forward model has 2 + Nd parameters
  {t, omega0, beta, t0, t1, ...}; 2 intrinsic ones and Nd extrinsic ones.

* Sample a noise distribution and whiten the signals in the individual
  detectors accordingly. Add summary information about the noise distribution
  to the signal array.

* Add white noise to the signals.

* Normalize the parameters.

* Convert arrays to Tensors.


Generation of observations
--------------------------
Network input ---> Observation

Observations are generated from network input data by undoing the whitening,
converting tensors to arrays and storing observed data and noise
distributions in separate dicts.


Inference Transformations
-------------------------
Observation ---> Network Input

In accordance with the training transformations, the observed data is
prepared for the neural network by the following sequence of transformations.

* Merge the observations in the separate detectors into one array.

* Add an empty channel for the noise summary.

* Whiten the signal data and add noise summary to the corresponding channel.

* Transform the arrays to tensors.
"""
from tutorials.toy_example_utils import *

# set up simulator
t_axis = [0, 10, 1000]
simulator = HarmonicOscillator(*t_axis)

# get dataset for intrinsic parameters
extrinsic_prior = [[3.0, 10.0], [0.2, 0.5]]
parameters = sample_from_uniform_prior(extrinsic_prior, num_samples=5_000)
simulations = simulator.simulate(parameters)
dataset = SimulationsDataset(parameters, simulations)

# add prior for extrinsic parameters
intrinsic_prior = [[0, 3], [2, 5]]
prior = extrinsic_prior + intrinsic_prior
Nd = len(intrinsic_prior)

############################
# Training Transformations #
############################

# build transformation objects
projection_kwargs = {
    'num_detectors': 2,
    'num_channels': 3,
    't_axis_delta': simulator.delta_t,
    'ti_priors_list': intrinsic_prior,
}
noise_module_kwargs = {
    'num_bins': simulator.N_bins,
    'std': 0.01,
}
normalization_kwargs = {
    'means': get_means_and_stds_from_uniform_prior_ranges(prior)[0],
    'stds': get_means_and_stds_from_uniform_prior_ranges(prior)[1],
}
transformation_kwargs = {
    'projection_kwargs': projection_kwargs,
    'noise_module_kwargs': noise_module_kwargs,
    'normalization_kwargs': normalization_kwargs,
}

transform_projection = ProjectOntoDetectors(**projection_kwargs)

noise_module = NoiseModule(**noise_module_kwargs)
transform_whiten_signal_and_add_noise_summary = \
    WhitenSignalAndGetNoiseSummary(noise_module)
transform_add_white_noise = AddWhiteNoise(noise_module)

transform_normalize_parameters = NormalizeParameters(
    **normalization_kwargs, inverse=False)
transform_denormalize_parameters = NormalizeParameters(
    **normalization_kwargs, inverse=True)

transform_to_tensors = DictElementsToTensor()

# get data from dataset, and visualize raw data
data = dataset[0]
print(data['parameters'])
plt.figure(figsize=(8, 2))
plt.title('Raw data')
plt.plot(simulator.t_axis, data['simulations'])
plt.show()

# sample intrinsic parameters, project onto the detectors
data = transform_projection(data)
print(data['parameters'])
fig, axs = plt.subplots(Nd, 1)
fig.set_size_inches(8, Nd * 2)
for idx in range(Nd):
    ax = axs[idx]
    ax.set_title('Projection onto detector {:}'.format(idx))
    ax.plot(simulator.t_axis, data['simulations'][idx, 0], label='real')
    ax.plot(simulator.t_axis, data['simulations'][idx, 1], label='imag')
    ax.plot(simulator.t_axis, data['simulations'][idx, 2], label='noise '
                                                                 'summary')
    ax.legend()
plt.show()

# sample a noise distributions for each detector and whiten projected signals
# accordingly; add noise distribution summary as additional context to the data
data = transform_whiten_signal_and_add_noise_summary(data)
print(data['parameters'])
fig, axs = plt.subplots(2 * Nd, 1)
fig.set_size_inches(8, 2 * Nd * 2)
for idx in range(Nd):
    (ax1, ax2) = axs[2 * idx], axs[2 * idx + 1]
    ax1.set_title('Whitened data in detector {:}'.format(idx))
    ax1.plot(simulator.t_axis, data['simulations'][idx, 0], label='real')
    ax1.plot(simulator.t_axis, data['simulations'][idx, 1], label='imag')
    ax1.legend()
    ax2.set_title('Noise summary in detector {:}'.format(idx))
    ax2.plot(simulator.t_axis, data['simulations'][idx, 2])
plt.show()

# add white noise to whitened signals
data = transform_add_white_noise(data)
print(data['parameters'])
fig, axs = plt.subplots(Nd, 1)
fig.set_size_inches(8, Nd * 2)
for idx in range(Nd):
    ax = axs[idx]
    ax.set_title('Noisy data in detector {:}'.format(idx))
    ax.plot(simulator.t_axis, data['simulations'][idx, 0], label='real')
    ax.plot(simulator.t_axis, data['simulations'][idx, 1], label='imag')
    ax.legend()
plt.show()

# normalize the parameters
data = transform_normalize_parameters(data)
print(data['parameters'])
print(transform_denormalize_parameters(data)['parameters'])

# convert numpy arrays to tensor
data = transform_to_tensors(data)
print(data['parameters'])

# for convenience, we will use a function to build the composite of all these
# transformations from kwargs
train_transform, _, _ = get_transformations_composites(**transformation_kwargs)

# apply the composite transformation to the first element of the dataset
data_transformed = train_transform(dataset[0])
print(data_transformed['parameters'])
assert torch.equal(data_transformed['parameters'][:2],
                   data['parameters'][:2]), 'Intrinsic parameters do not match.'
# we observe that as expected the intrinsic parameters match, but the
# extrinsic ones don't. These are sampled from the prior when the
# transformations are applied, so they are different every time.
fig, axs = plt.subplots(2 * Nd, 1)
fig.set_size_inches(8, 2 * Nd * 2)
for idx in range(Nd):
    (ax1, ax2) = axs[2 * idx], axs[2 * idx + 1]
    ax1.set_title('Noisy data in detector {:}'.format(idx))
    ax1.plot(simulator.t_axis, data['simulations'][idx, 0],
             label='Extrinsic parameters 1')
    ax1.plot(simulator.t_axis, data_transformed['simulations'][idx, 0],
             label='Extrinsic parameters 2')
    ax1.legend()
    ax2.set_title('Noise summary in detector {:}'.format(idx))
    ax2.plot(simulator.t_axis, data['simulations'][idx, 2],
             label='Noise summary information 1')
    ax2.plot(simulator.t_axis, data_transformed['simulations'][idx, 2],
             label='Noise summary information 2')
    ax2.legend()
plt.show()

##############################
# Generation of observations #
##############################

# generate some simulated input
noise_module = NoiseModule(**noise_module_kwargs)
data = dataset[0]
data = train_transform(data)
# separate signal from noise
observations_white = np.array(data['simulations'][:, :2, :])
noise_distributions = np.array(
    noise_module.get_noise_distribution_from_summary(
        data['simulations'][:, 2, :]
    )
)
# undo the whitening
observations = np.zeros_like(observations_white)
for idx in range(Nd):
    observations[idx] = observations_white[idx] * noise_distributions[idx]
# visualize the observed data
fig, axs = plt.subplots(2 * Nd, 1)
fig.set_size_inches(8, 2 * Nd * 2)
for idx in range(Nd):
    (ax1, ax2) = axs[2 * idx], axs[2 * idx + 1]
    ax1.set_title('Noisy data in detector {:}'.format(idx))
    ax1.plot(simulator.t_axis, observations_white[idx, 0],
             label='Whitened')
    ax1.plot(simulator.t_axis, observations[idx, 0],
             label='Not whitened')
    ax1.legend()
    ax2.set_title('Noise distribution in detector {:}'.format(idx))
    ax2.plot(simulator.t_axis, noise_distributions[idx])
plt.show()
# in reality, the observed data could be stored in a dict
observations = {
    'Detector{:}'.format(idx): observations[idx] for idx in range(Nd)
}
noise_distributions = {
    'Detector{:}'.format(idx): noise_distributions[idx] for idx in range(Nd)
}
sample = {
    'simulations': observations,
    'noise_distributions': noise_distributions,
}

# these transformations are also generated by get_transformations_composites
_, generate_observations_transform, _ = get_transformations_composites(
    **transformation_kwargs)
sample_ = generate_observations_transform(data)
for key0, item0 in sample.items():
    for key1, item1 in item0.items():
        assert np.array_equal(item1, sample_[key0][key1]), \
            'Transformation object is not equivalent to transformations ' \
            'implemented above.'

#############################
# Inference Transformations #
#############################

# We now want to build a sequence of transformations that transforms this
# observed data to input tensors for the neural network, in a way that
# corresponds to the transformations applied at training time. This requires
# creating a single numpy array out of the dicts, whitening and conversion of
# the resulting array to a torch tensor.

transform_dicts_to_array = ConvertDictsToArray()
transform_add_noise_summary_channel = AddContextChannels('simulations', 1)
noise_module = NoiseModule(**noise_module_kwargs)
transform_whiten_signal_and_add_noise_summary = \
    WhitenSignalAndGetNoiseSummary(noise_module)
transform_to_tensors = DictElementsToTensor()

sample = transform_dicts_to_array(sample)
sample = transform_add_noise_summary_channel(sample)
sample = transform_whiten_signal_and_add_noise_summary(sample)
sample = transform_to_tensors(sample)
assert np.array_equal(sample['simulations'], data['simulations'])
fig, axs = plt.subplots(2 * Nd, 1)
fig.set_size_inches(8, 2 * Nd * 2)
for idx in range(Nd):
    (ax1, ax2) = axs[2 * idx], axs[2 * idx + 1]
    ax1.set_title('Noisy data in detector {:}'.format(idx))
    ax1.plot(simulator.t_axis, sample['simulations'][idx, 0])
    ax1.plot(simulator.t_axis, data['simulations'][idx, 0])
    ax2.set_title('Noisy summary in detector {:}'.format(idx))
    ax2.plot(simulator.t_axis, sample['simulations'][idx, 2])
    ax2.plot(simulator.t_axis, data['simulations'][idx, 2])
plt.show()

# these transformations are also generated by get_transformations_composites
_, _, inference_transform = get_transformations_composites(
    **transformation_kwargs)
sample_ = inference_transform(sample_)
assert np.array_equal(sample['simulations'], sample_['simulations'])
